// The generated lexer module will start with this code
{
module Lexer
open Microsoft.FSharp.Text.Lexing
// open the module that defines the tokens
open System
open Parser
}

// We define macros for some regular expressions we will use later
let digit       = ['0'-'9']
//let num         = ('+'|'-')? digit+ ( '.' digit+)?  ('E' ('+'|'-')? digit+ )?
let num         = digit+ ( '.' digit+)?  ('E' ('+'|'-')? digit+ )?
let xval        = ['a'-'z''A'-'Z']['a'-'z''A'-'Z']*
let whitespace  = [' ' '\t']
let newline     = "\n\r" | '\n' | '\r'

// We define now the rules for recognising and building tokens
// for each of the tokens of our language we need a rule
rule tokenize = parse
// deal with tokens that need to be ignored (skip them)
| whitespace    { tokenize lexbuf }
| newline       { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }
// deal with tokens that need to be built
| num           { NUM(Double.Parse(LexBuffer<_>.LexemeString lexbuf)) }
| xval          { XVAR((LexBuffer<_>.LexemeString lexbuf)) }
| '*'           { TIMES }
| '/'           { DIV }
| '+'           { PLUS }
| '-'           { MINUS }
| '^'           { POW }
| '('           { LPAR }
| ')'           { RPAR }
| '['           { LSPAR }
| ']'           { RSPAR }
| '&'           { BITAND }
| '|'           { BITOR }
| "||"          { OR }
|'&''&'         { AND}
| '!'           { NOT }
| '='           { EQUAL}
| "!="          { NEQUAL}
| '>'           { GREATER}
| ">="          { GREATEREQ }
| '<'           { LESSER }
| "<="          { LESSEREQ }
| "->"          { ARROW }
| ":="          { ASSIGN }
| "skip"        { SKIP }
| ';'           { STATE }
| "if"          { IF }
| "fi"          { FI }
| "do"          { DO }
| "od"          { OD }
| eof           { EOF }
